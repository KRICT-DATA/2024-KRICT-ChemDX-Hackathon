{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hojechun/miniconda3/envs/krict/lib/python3.10/site-packages/e3nn/o3/_wigner.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from mace.calculators import mace_mp\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Materials Project MACE for MACECalculator with /Users/hojechun/.cache/mace/5yyxdm76\n",
      "Using float32 for MACECalculator, which is faster but less accurate. Recommended for MD. Use float64 for geometry optimization.\n",
      "Default dtype float32 does not match model dtype float64, converting models to float32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hojechun/miniconda3/envs/krict/lib/python3.10/site-packages/mace/calculators/mace.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model = mace_mp(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num for handcrafted features: 64\n"
     ]
    }
   ],
   "source": [
    "# Select columns that start with 'fp'\n",
    "handcrafted_features = pd.read_csv(\"datasets/processed/parsed_dataset_normalized.csv\")\n",
    "fp_columns = [col for col in handcrafted_features.columns if col.startswith('num')]\n",
    "# Concatenate these columns into a single feature vector column\n",
    "handcrafted_features['feature_vector'] = handcrafted_features[fp_columns].apply(lambda row: np.array(row), axis=1)\n",
    "print(f\"Num for handcrafted features: {len(handcrafted_features['feature_vector'][0])}\")\n",
    "# Convert the column with dictionary-like strings to actual dictionaries\n",
    "\n",
    "# Updated function with error handling for non-JSON compatible strings\n",
    "def parse_atoms(x):\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            # Replace \"array\" with \"np.array\" to interpret as numpy arrays\n",
    "            formatted_str = x.replace(\"array\", \"np.array\").replace(\"'\", '\"')\n",
    "            # Evaluate with restricted environment allowing only np.array\n",
    "            return eval(formatted_str, {\"np\": np})\n",
    "        except (SyntaxError, NameError, ValueError) as e:\n",
    "            print(f\"Error decoding row: {x}\\nError: {e}\")\n",
    "            return {}  # Return an empty dictionary if parsing fails\n",
    "    return {}  # Return empty dict if x is not a string\n",
    "\n",
    "# Apply the parsing function with error handling\n",
    "handcrafted_features['atoms'] = handcrafted_features['atoms'].apply(parse_atoms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4452it [03:35, 20.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from ase import Atoms\n",
    "\n",
    "# Initialize an empty dictionary for the new dataset\n",
    "new_dataset = {}\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for idx, row in tqdm(handcrafted_features.iterrows()):\n",
    "    # Extract values for each field from the current row\n",
    "    value_per_atom = row['value_per_atom']\n",
    "    h_feat = row['feature_vector']\n",
    "    atoms = row['atoms']\n",
    "    \n",
    "    # Create the Atoms object using the dictionary in 'atoms' column\n",
    "    descriptor = np.mean(model.get_descriptors(Atoms.fromdict(atoms)), axis=0)\n",
    "    \n",
    "    # Add the data to the new_dataset dictionary\n",
    "    new_dataset[row['id']] = {\n",
    "        \"id\": row[\"id\"],\n",
    "        \"atoms\": atoms,\n",
    "        \"descriptor\": descriptor,\n",
    "        \"descriptor_2\": h_feat,\n",
    "        \"value_per_atom\": value_per_atom,\n",
    "        \"natoms\": len(Atoms.fromdict(atoms))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num for handcrafted features: 256\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num for handcrafted features: {len(new_dataset[list(new_dataset.keys())[0]]['descriptor'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump((new_dataset,handcrafted_features['mean'][0], handcrafted_features['std'][0]), open(\"datasets/processed/processed_dataset.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f184328288171e7e409a9007fe7529271c183859d832b8382a0e88a5e14cee45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
